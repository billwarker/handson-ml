{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on Machine Learning - Chapter 1 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of ML\n",
    "- ML: algorithms learning from data and improving performance on a task\n",
    "- Advantage over rule based systems is that machine can update parameters/logic with new/more data (refreshing the model)\n",
    "- Applying ML to discover/understand patterns in the data: data mining\n",
    "\n",
    "- Supervised learning: training a model with labelled examples. can be used for classification tasks (predict a discrete category) or regression (predict a continuous number)\n",
    "\n",
    "- unsupervised learning algos: clustering unlabelled data, visualizing and dimensionality reduction, association rule learning\n",
    "- hierarchical clustering: sub-dividing clusters into smaller groups\n",
    "- dimensionality reduction: simplify data without losing too much information. i.e. merging correlated features. can help performance, takes up less disk and memory space\n",
    "- anomoly detection\n",
    "- association rule learning: relations between attributes (similar to data mining)\n",
    "\n",
    "- Semi-supervised learning. i.e. Google Photos, looks at unlabelled pictures to find common faces. once given a label for a person it can name everyone in the photo. mixed hierarchical models\n",
    "\n",
    "- Reinforcement learning: agent learns its environment and selects a policy (actions, strategy) to optimize some reward\n",
    "\n",
    "Batch vs. Online Learning\n",
    "- Batch: training a model on all available data. train the system and then put it in prod. retrain new versions of the model with new data\n",
    "- requires a lot of computing resources, can be expensive. not suitable for autonomous systems with limited space for data (i.e. Mars rover)\n",
    "\n",
    "- Online: train system incrementally on mini-batches of data\n",
    "- great for continuous flows of data or limited storage resources\n",
    "- can be used to train on datasets that won't fit in memory (out-of-core learning)\n",
    "\n",
    "- learning rate: how fast model adapts to new data\n",
    "- too high, forgets old data rapidly, too low, system has inertia (also less sensitive to noisey data)\n",
    "- need to monitor online systems if garbage data starts coming in\n",
    "\n",
    "Instance-Based vs. Model-Based Learning\n",
    "- how a system generalizes (i.e. answers examples its never seen before)\n",
    "- Instance-based: generalizes to new examples by comparing similarity to training examples\n",
    "- i.e. KNN\n",
    "- Model-based: builds a model to predict new data\n",
    "- select a model (i.e. linear model) to represent the data's pattern\n",
    "- tune model on a utility or cost function\n",
    "\n",
    "- if a model doesn't generalize well, you can try again with better quality training data, more features, or a stronger model (e.g. polynomial vs. basic linear)\n",
    "- adding more data tends to get better results on all kinds of algos, to the point where performance can be identical with enough data\n",
    "- data needs to be representitive of the problem space trying to model, more data can eliminate noise but procedure needs to be solid or it risks sampling bias\n",
    "\n",
    "Feature Engineering\n",
    "- feature selection, picking the most useful features\n",
    "- feature extraction, combining existing features to produce more useful ones + dimensionality reduction\n",
    "- creating new features with the intro of new data\n",
    "\n",
    "Performance\n",
    "- overfitting: performing well on the training data but not generalizing well\n",
    "- machine learning can pick up on noise in the data and sometimes even irrelevant features/useless metadata (i.e. data ids/index), detecting false patterns\n",
    "- overfitting happens when the model is too complex relative to the amount and noiseness of the data\n",
    "- regularization is constraining a model to make it simpler can help overfitting\n",
    "- controlled by model hyperparameters (knobs to tweak on the model itself, such as learning rate)\n",
    "- underfitting is opposite problem, model is too simple\n",
    "- fix it with a more complex model, more/better features, reducing regularization constraints\n",
    "\n",
    "- test models to see if they generalize well\n",
    "- split data into training and test sets to get error rate on new cases (out of sample/generalization error)\n",
    "- if training error is now but oos error is high, overfitting\n",
    "- use a third validation set to compare models/hyperparameters, then select the best one and use it one the test\n",
    "- cross validation splits the training set into subsets which are used for validation\n",
    "\n",
    "- need to make assumptions about the data to pick models reasonably\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you define ML?\n",
    "- Algorithms that allow a computer to learn from data to improve on a task and generalize to new examples well\n",
    "\n",
    "Four types of problems where it shines?\n",
    "- Problems that traditionally require too many rules or hand-tuning\n",
    "- Complex problems with no easy logic based model\n",
    "- Problems where underlying strategy/solutions change over time, so new model can help adapt\n",
    "- Data mining, learning underlying patterns in data\n",
    "\n",
    "What is a labelled training set?\n",
    "- Data that has the variable of interest classified (independent variable), and information about it in other attribures (dependent variables)\n",
    "\n",
    "Two most common supervised tasks?\n",
    "- Regression: predicting a continuous number for the target variable\n",
    "- Classification: predicting a discrete category of target variable\n",
    "\n",
    "Four kinds of unsupervised tasks?\n",
    "- Clustering: creating groups in unstructured data\n",
    "- Dimesionality Reduction: reducing the number of attributes in the training set while keeping most of the variance(underlying signal)\n",
    "- Anomoly Dection: finding outliers\n",
    "- Visualization\n",
    "- Association Rule learning: data mining, learning patterns in the data\n",
    "\n",
    "What type of ML algo would you use to allow a robot to walk in various unknown terrains?\n",
    "- Reinforcement Learning\n",
    "\n",
    "What type of algo would you use to segment your customers into multiple groups?\n",
    "- Clustering, Unsupervised Learning\n",
    "\n",
    "Would you frame the problem of spam detection as a supervised learning problem?\n",
    "- Supervised; we can use examples of spam and ham (labelled training data) to create a model that identifies which is which\n",
    "\n",
    "What is an online learning system?\n",
    "- A system that can update with new data as it comes in, ingesting as it comes in through mini-batches\n",
    "\n",
    "What is an out-of-core learning system?\n",
    "- Using online learning to train the model on a dataset that wouldn't fit inside the computers memory if you tried to train it in one giant batch.\n",
    "\n",
    "What type of learning algo relies on similarity measures to make predictions?\n",
    "- Instanced-based models, i.e. KNN\n",
    "\n",
    "Difference between a model parameter and a hyperparameter?\n",
    "- A model parameter is the coefficient determined by the algorithm to apply to a attribute/feature in the data when making predictions, a hyperparameter is an aspect of the model that you can adjust to change how it is trained\n",
    "\n",
    "What do model-based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?\n",
    "- These algo's look to fit the model to the data (i.e. represent the problem with some simplified version of it). The strategy is to improve performance in respect to some cost/utility function. They make new predictions by applying the policy/parameters determined through training on the new data's features\n",
    "\n",
    "Four main challenges in ML?\n",
    "- Not enough data\n",
    "- Non-representative data\n",
    "- Poor quality data\n",
    "- Overfitting/Underfitting\n",
    "\n",
    "If a model performs well on the training data but generalizes poorly to new examples, what is happening? 3 possible solutions?\n",
    "- Model is overfitting to the training data and can't generalize well to the new examples\n",
    "- You can regularize the model (i.e. constrain it) to be less representative of the training data\n",
    "- Train the model on more data/more representative data\n",
    "- Tune the model on a validation set\n",
    "\n",
    "What is a test set and why would you want to use it?\n",
    "- Test the performance of the model on new examples to understand how well it generalizes to new data (i.e. the whole point)\n",
    "\n",
    "What can go wrong if you tune hyperparameters on the test set?\n",
    "- You fit the model to work well on the testing set, overfitting it and reducing the chance of generalizing well\n",
    "\n",
    "What is cross validation, why is it better than a validation set?\n",
    "- Cross validation takes different chunks of the training data and uses them iteratively to train and validate the model, creating a more robust model (training on different samples) and is a more economic use of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
